{"cells":[{"cell_type":"markdown","metadata":{"id":"imeKz8r11Ftx"},"source":["# <font color='green'><b> Edge detection </b></font>\n","\n","\n","### Credits: Hands-on Image Processing with Python, Chapter 5 - Author: Sandipan Dey\n"]},{"cell_type":"markdown","metadata":{"id":"Aja4PWPW1U2_"},"source":["## <font color='green'><b>Base Dir setup</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ▶️ Base dir setup\n","import os, sys\n","\n","# check if hosted (Google VM) or running on local server\n","if 'google.colab' in sys.modules:\n","  #@markdown Google Drive root folder - hosted by Google VM (adapt to your local paths)\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=False)\n","  base_dir = 'CV/' #@param {type: \"string\"}\n","  base_dir  = os.path.join('/content/drive/MyDrive/', base_dir)\n","  #MODIFY THESE PATHS TO POINT TO YOUR IMAGES\n","  img_dir = 'data/img/'\n","  vid_dir = 'data/video/'\n","  out_dir = 'output/'\n","  \n","  # move to base_dir \n","  os.chdir(base_dir)\n","else:\n","  #MODIFY THESE PATHS TO POINT TO YOUR IMAGES\n","  img_dir = '../data/img/'\n","  out_dir = '../data/output/'\n","\n","print(\"Current dir:\", os.getcwd())"]},{"cell_type":"markdown","metadata":{},"source":["## <font color='green'><b>Import libraries</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOvc2JQMYpCo"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import plotly.express as px       # TUTORIAL: https://plotly.com/python/getting-started/\n","import plotly.graph_objects as go \n","import math\n","from plotly.subplots import make_subplots  \n","from skimage.io import imread\n","from skimage.color import rgb2gray\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agPUlzoyK7yw"},"outputs":[],"source":["def multiPlots(images, titles= [], nCols = 2):\n","\n","  '''multiPlots funtion allows to plot a list of images organized on nCols, with possible titles'''\n","  \n","  plt.gray() \n","  nImg =len(images)\n","  nRows = math.ceil(nImg/nCols) \n","  f = plt.figure(figsize=(10,4*nRows))\n","\n","  for n, image in enumerate(images): \n","    row = int(n/nCols)+1\n","    col = n%nCols+1\n","    ax = f.add_subplot(nRows, nCols, n+1)\n","    ax.imshow(image, cmap='gray')   \n","    plt.axis('off')\n","    if titles:\n","      plt.title(titles[n]) \n"]},{"cell_type":"markdown","metadata":{"id":"QXEeEUnb8uhK"},"source":["## <font color='green'><b>Load an Image</b></font>\n","\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"elapsed":2068,"status":"ok","timestamp":1666602376344,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"zrYV_em1-MDv","outputId":"c7d87157-0e36-4cc0-c3d3-d9263c5d526b"},"outputs":[],"source":["# load an example image \n","img = imread(img_dir +  'goldengate.jpg')\n","\n","# show image (RGB and Gray)\n","plt.figure(figsize=(10,5))\n","plt.subplot(121)\n","plt.imshow(img)\n","grayImg = rgb2gray(img)\n"," \n","plt.subplot(122)\n","plt.imshow(grayImg, cmap='gray')\n","plt.show()\n","#print(grayImg.dtype)"]},{"cell_type":"markdown","metadata":{"id":"6DQX3XiP9REr"},"source":["### <font color='green'><b>Edge detection via 1st and 2nd order derivatives with the *Opencv*</b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"Fq7QqVqx-Zj7"},"source":["*Goal:*\n","\n","We will learn to use the functions cv2.Sobel(), cv2.Scharr(), cv2.Laplacian()\n"," \n","**Theory**\n","\n","OpenCV provides three types of gradient filters or High-pass filters, Sobel, Scharr and Laplacian. We will see each one of them.\n","\n","**1. Sobel Derivatives**\n","\n","Sobel operators is a joint Gaussian smoothing plus differentiation operation, so it is more resistant to noise. You can specify the direction of derivatives to be taken, vertical or horizontal (by the arguments, yorder and xorder respectively). You can also specify the size of kernel by the argument ksize.  \n","\n","\n","$Sobel Operator [X-axis] = \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1  \\end{bmatrix}$\n","\n","$Sobel Operator [Y-axis] = \\begin{bmatrix} 1 & 2 & 1 \\\\ 0 & 0 & 0 \\\\ -1 & -2 & -1  \\end{bmatrix}$\n","\n","**2. Scharr Filters**\n","\n","Scharr as a kernel so defined:\n"," \n","$Scharr Operator [X-axis] = \\begin{bmatrix} -3 & 0 & 3 \\\\ -10 & 0 & 10 \\\\ -3 & 0 & 3  \\end{bmatrix}$\n","\n","$Scharr Operator [Y-axis] = \\begin{bmatrix} 3 & 10 & 3 \\\\ 0 & 0 & 0 \\\\ -3 & -10 & -3  \\end{bmatrix}$\n","\n","Schould be more precise than Sobel\n"," \n","\n","\n","**3. Laplacian Derivatives**\n","\n","It calculates the Laplacian of the image given by the relation, $\\Delta(src) = \\frac{\\partial ^2{src}}{\\partial x^2} + \\frac{\\partial ^2{src}}{\\partial y^2}$ where each derivative is found using Sobel derivatives. If ksize = 1, then following kernel is used for filtering:\n","\n","$kernel = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0  \\end{bmatrix}$\n","\n","**Code**\n","\n","Below code shows all operators in a single diagram. To get the result in floating point pass cv2.CV_64F as Depth of output image "]},{"cell_type":"markdown","metadata":{"id":"auHOfainN6CK"},"source":["### <font color='green'><b> Gradient via Prewitt </b></font>\n","\n","\n","Before using the built-in functions, let start defining the Prewitt kernel, applying it with the `cv2.filter2D` function.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD5SNcSTHT6a"},"outputs":[],"source":["#define the kernel for the partial derivative  in y\n","kernel_y = np.array([[-1, -1, -1],\n","                     [0 ,  0,  0],\n","                     [1 ,  1,  1]]); \n","\n","# the kernel for the  x-derivative is the transpose of \"kernel_y\"\n","kernel_x = np.transpose(kernel_y); \n","\n","#partial derivatives\n","gy = cv2.filter2D(grayImg, -1, kernel_y); #https://www.tutorialspoint.com/opencv/opencv_filter2d.htm\n","gx = cv2.filter2D(grayImg, -1, kernel_x);  \n","#print(gy.dtype)\n","\n","#magnitude\n","magnitude = np.sqrt(gx**2 + gy**2)\n","magnitude /= np.max(magnitude);\n","magnitude = np.uint8(magnitude*255);\n","\n","#orientation\n","theta = cv2.phase(np.array(gx ), np.array(gy), angleInDegrees=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot Orientations (skip details)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_orientations(theta):\n","      #INPUT: theta: orientation maps\n","  \n","  image_map = np.zeros((theta.shape[0], theta.shape[1], 3), dtype=np.int16)\n","\n","  # Define RGB colours\n","  red = np.array([255, 0, 0])\n","  cyan = np.array([0, 255, 255])\n","  green = np.array([0, 255, 0])\n","  yellow = np.array([255, 255, 0])\n","\n","  # Set colours corresponding to angles\n","  for i in range(0, image_map.shape[0]):\n","    for j in range(0, image_map.shape[1]):\n","        if theta[i][j] < 90.0:\n","            image_map[i, j, :] = red\n","        elif theta[i][j] >= 90.0 and theta[i][j] < 180.0:\n","            image_map[i, j, :] = cyan\n","        elif theta[i][j] >= 180.0 and theta[i][j] < 270.0:\n","            image_map[i, j, :] = green\n","        elif theta[i][j] >= 270.0 and theta[i][j] < 360.0:\n","            image_map[i, j, :] = yellow\n","\n","  # Display gradient orientation\n","  f, ax1 = plt.subplots(1, 1, figsize=(5,4))\n","\n","  ax1.set_title('gradient orientation')\n","  ax1.imshow(image_map)\n","  ax1.axis('off')\n","  return image_map.astype('uint8')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["##### - variant: **plot_orientationsMASK**\n","As we can see, the magnitude and orientation are computed at each position (x,y). \n","\n","However, not all these values are relevant.\n","Let's try to clean up these maps.\n"," \n","**1. Cleaning criterion:**\n","- TH = 98 percentile of the magnitude \n","\n","- if magnitude(x,y) < TH than\n","    magnitude(x,y) =0 \n","    orientation = -1 \n"," \n","**2. Plot the cleaned orientation map**\n","Observe that, to plot the cleaned orientation map, you should modify the plot_orientations function (let call the modified function `plot_orientationsMASK`) so that, in case of value -1, it plots black."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_orientationsMASK (theta, magnitude, perc=95):\n","    \n","    '''This function plot the theta corresponding to the strongest magnitude values\n","        INPUT: \n","            - theta: orientation maps\n","            - magnitude: magnitude of the gradient\n","            - percentile: percentile of the strongest magnitude'''\n","\n","    image_map = np.zeros((theta.shape[0], theta.shape[1], 3), dtype=np.int16)\n","\n","    #1. Determine the threshold as a certain percentile of the magnitude\n","    TH =  np.percentile(magnitude, perc) \n","\n","    #2. Clean the theta and mag maps accordingly\n","    theta[magnitude < TH] = -1;\n"," \n","    # Define RGB colours\n","    red = np.array([255, 0, 0])\n","    cyan = np.array([0, 255, 255])\n","    green = np.array([0, 255, 0])\n","    yellow = np.array([255, 255, 0])\n","\n","    # Set colours corresponding to angles\n","    for i in range(0, image_map.shape[0]):\n","        for j in range(0, image_map.shape[1]):\n","            if theta[i][j] < 90.0 and theta[i][j] >0:  # JUST EXCLUDE THE NEGATIVE VALUES FROM THIS CASE, \n","                                                   # LEAVING THEM TO ZERO AS IN THE INITIALIZATION\n","                image_map[i, j, :] = red\n","            elif theta[i][j] >= 90.0 and theta[i][j] < 180.0:\n","                image_map[i, j, :] = cyan\n","            elif theta[i][j] >= 180.0 and theta[i][j] < 270.0:\n","                image_map[i, j, :] = green\n","            elif theta[i][j] >= 270.0 and theta[i][j] < 360.0:\n","                image_map[i, j, :] = yellow\n","\n","    # Display gradient orientation\n","    f, ax1 = plt.subplots(1, 1, figsize=(10,5))\n","\n","    ax1.set_title('gradient orientation')\n","    ax1.imshow(image_map)\n","    return image_map"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":608},"executionInfo":{"elapsed":1681,"status":"ok","timestamp":1666602385696,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"sqlB27oTIgBR","outputId":"1406dac9-ee69-41fd-801a-53efbb8e3b25"},"outputs":[],"source":["# visualization:\n","\n","multiPlots ([img, magnitude, gx, gy], \n","            ['Original', 'Magnitude', 'Horizontal derivative', 'Vertical derivative'])\n","\n","plot_orientationsMASK(theta, magnitude);\n","#plot_orientations(theta);"]},{"cell_type":"markdown","metadata":{"id":"4JwVcJeWQqPk"},"source":["#### <font color='green'><b>EXERCISE 1: </b></font>\n","\n","1. Define the Sobel kernels,\n","2. extract the partial derivatives, \n","3. compute the magnitude, and  \n","4. the phase (hint: use the function cv2.phase, search documentation at: https://docs.opencv.org/)\n","\n","5. Then, plot the magnitude and the orientation maps, this last using the given function `plot_orientations` or `plot_orientationsMASK` "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 1\n","\n","#1. Define the 3x3 sobel filters sobel_x and sobel_y for edge detection\n"," \n"," \n","#2. Filter the grayscale image using the defined filters and the cv2.filter2D funcion\n","\n","\n","#3. Compute the magnitude 'magnitude'\n","\n","\n"," \n","#4. Compute the orientations 'theta'\n","\n","\n","#5. visualizations\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":655},"executionInfo":{"elapsed":1752,"status":"ok","timestamp":1666602391225,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"rJjTMLd5T1wp","outputId":"8ac97627-ac9e-4f81-801a-e20546fd2d4d"},"outputs":[],"source":["#SOLUTION EX 1\n","\n","#1. Define the 3x3 sobel filters sobel_x and sobel_y for edge detection\n"," \n","sobel_x = np.array([[ -1, 0, 1], \n","                   [ -2, 0, 2], \n","                   [ -1, 0, 1]])\n","sobel_y = np.transpose(sobel_x)\n"," \n","#2. Filter the grayscale image using the defined filters and the cv2.filter2D funcion\n","sobel_x = cv2.filter2D(grayImg, -1, sobel_x)  \n","sobel_y = cv2.filter2D(grayImg, -1, sobel_y)\n","\n","#3. Compute the magnitude 'magnitude'\n","\n","#magnitude\n","magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n","magnitude /= np.max(magnitude);\n","magnitude = np.uint8(magnitude*255);\n"," \n","#4. Compute the orientations 'theta'\n","theta = cv2.phase(np.array(sobel_x ), np.array(sobel_y), angleInDegrees=True)\n","\n","#5. visualizations\n","plt.figure(figsize=(5,4))\n","plt.imshow(magnitude, cmap='gray')\n","plt.title('gradient magnitude')\n","theta_map = plot_orientations(theta)\n","\n","fig = px.imshow(gx, color_continuous_scale='gray', title='gx')\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":818,"status":"ok","timestamp":1666602399378,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"YrVlcnX5dQez","outputId":"9211cd3d-5598-4bae-c585-e7cc7805332e"},"outputs":[],"source":["#Plot the phase in correspondence of the high values of magnitude only:\n","theta_map = plot_orientationsMASK(theta, magnitude, 95) \n"]},{"cell_type":"markdown","metadata":{"id":"GQ2kR1uS-VKA"},"source":["### <font color='green'><b>Gradient via Sobel built-in </b></font>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":909},"executionInfo":{"elapsed":2034,"status":"ok","timestamp":1666602407613,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ScNr9HFa-o1i","outputId":"93bc95dd-627a-44e0-d742-1831ff13ac04"},"outputs":[],"source":["# SOBEL\n","sobelx = cv2.Sobel(grayImg, -1,1,0) #last 2 parameters: x_order and y_order\n","sobely = cv2.Sobel(grayImg, -1,0,1)\n","\n","mag = cv2.magnitude(sobelx, sobely)\n","theta = cv2.phase(np.array(sobelx), np.array(sobely), angleInDegrees=True)\n","\n","theta_map = plot_orientationsMASK(theta, mag, 95) \n","multiPlots([grayImg, mag, sobelx, sobely ], ['Original', 'Magnitude','Sobel X', 'Sobel Y'])\n","  "]},{"cell_type":"markdown","metadata":{"id":"ek2noo7N9nS4"},"source":["### <font color='gray'><b>Gradient via Scharr built-in </b></font>\n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":909},"executionInfo":{"elapsed":1791,"status":"ok","timestamp":1666602412206,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"viSTmDqz9pmL","outputId":"b032ff02-878c-4b3c-e33b-cc54711cf6b6"},"outputs":[],"source":["# SCHARR\n","scharrx = cv2.Scharr(grayImg, cv2.CV_64F,1,0)  \n","scharry = cv2.Scharr(grayImg, cv2.CV_64F,0,1)\n","\n","mag = cv2.magnitude(scharrx, scharry)\n","theta = cv2.phase(np.array(scharrx), np.array(scharry), angleInDegrees=True)\n","\n","theta_map = plot_orientationsMASK(theta, mag, 95) \n","multiPlots([grayImg, mag, scharrx, scharry ], ['Original', 'Magnitude','Scharr X', 'Scharr Y'])\n","  "]},{"cell_type":"markdown","metadata":{"id":"cMyBoAFrUG1P"},"source":["\n","### <font color='green'><b>Second order derivative: the Laplacian </b></font>"]},{"cell_type":"markdown","metadata":{"id":"uDVV2F1aTgh1"},"source":["#### Zero Crossing (skip details)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JaE3pPgOkuR8"},"outputs":[],"source":["def Zero_crossing(image):\n","#INPUT: image: image filtered with the Laplacian\n","\n","    z_c_image = np.zeros(image.shape)\n","    \n","    # For each pixel, count the number of positive\n","    # and negative pixels in the neighborhood\n","    \n","    for i in range(1, image.shape[0] - 1):\n","        for j in range(1, image.shape[1] - 1):\n","            negative_count = 0\n","            positive_count = 0\n","            neighbour = [image[i+1, j-1],image[i+1, j],image[i+1, j+1],image[i, j-1],image[i, j+1],image[i-1, j-1],image[i-1, j],image[i-1, j+1]]\n","            d = max(neighbour)\n","            e = min(neighbour)\n","            for h in neighbour:\n","                if h>0:\n","                    positive_count += 1\n","                elif h<0:\n","                    negative_count += 1\n"," \n"," \n","            # If both negative and positive values exist in \n","            # the pixel neighborhood, then that pixel is a \n","            # potential zero crossing\n","            \n","            z_c = ((negative_count > 0) and (positive_count > 0))\n","            \n","            # Change the pixel value with the maximum neighborhood\n","            # difference with the pixel\n"," \n","            if z_c:\n","                if image[i,j]>0:\n","                    z_c_image[i, j] = image[i,j] + np.abs(e)\n","                elif image[i,j]<0:\n","                    z_c_image[i, j] = np.abs(image[i,j]) + d\n","                \n","    # Normalize and change datatype to 'uint8' (optional)\n","    z_c_norm = z_c_image/z_c_image.max()*255\n","    z_c_image = np.uint8(z_c_norm)\n"," \n","    return z_c_image"]},{"cell_type":"markdown","metadata":{"id":"qm01xhOX_Mpm"},"source":["\n","#### <font color='green'><b>The opencv function to apply the Laplacian to an image</b></font>\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1aBU60Ra943ys8DtyiZhhnZsLajKf-o1F"},"executionInfo":{"elapsed":4885,"status":"ok","timestamp":1666602422717,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"sNLcRxqElC-E","outputId":"62b8c671-af89-43f3-9710-e4a4af05ae4d"},"outputs":[],"source":["# LAPLACIAN\n","\n","laplacian = cv2.Laplacian(grayImg,-1) \n","ZC = Zero_crossing(laplacian)\n","fig = px.imshow(laplacian, color_continuous_scale='gray', title= 'Laplacian')\n","fig.show()\n","fig = px.imshow(ZC, color_continuous_scale='gray', title='Zero Crossing')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"piEh-bvSl11m"},"source":["### <font color='gray'><b>Edge detection with Skimage</b></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4192,"status":"ok","timestamp":1666602428128,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"t0iD7yY5lzSr","outputId":"c4f61b0e-b78b-41ea-b16e-30e425e46990"},"outputs":[],"source":["from skimage import filters, feature, img_as_float\n","\n","plt.gray()\n","images = []\n","titles = []\n","\n","images.append(grayImg)\n","titles.append('original')\n","\n","\n","rob = filters.roberts(grayImg)\n","images.append(rob)\n","titles.append('roberts')\n","\n","sch = filters.scharr(grayImg)\n","images.append(sch)\n","titles.append('scharr')\n","\n","sob_x = filters.sobel_h(grayImg)\n","images.append(sob_x)\n","titles.append('sobel_x') \n","\n","sob_y = filters.sobel_v(grayImg)\n","images.append(sob_x)\n","titles.append('sobel_y') \n","\n","sob = filters.sobel(grayImg)\n","images.append(sob)\n","titles.append('sobel') \n","\n","prew = filters.prewitt(grayImg)\n","images.append(sob_x)\n","titles.append('prewitt')\n","\n","lap = filters.laplace(grayImg)\n","images.append(sob_x)\n","titles.append('laplace')\n","\n","ZC = Zero_crossing(lap) #my function\n","images.append(ZC)\n","titles.append('zero crossing')\n","\n","multiPlots(images, titles, 3)"]},{"cell_type":"markdown","metadata":{"id":"i8ofZM3H_92V"},"source":["## <font color='green'><b>Marr-Hildreth algorithm </b></font>"]},{"cell_type":"markdown","metadata":{"id":"hNhiVTLxp3Nn"},"source":["#### <font color='green'><b>EXERCISE 2: </b></font>\n","  \n","Implement the Marr-Hildreth algorithm as a function, either drawing the LoG mask directly implementing:\n","\n","\n","$\\begin{bmatrix}\n","0 & 0 & -1 & 0 & 0 \\\\\n","0 & -1 & -2 & -1 & 0 \\\\\n","-1 & -2 & 16 & -2 & -1 \\\\\n","0 & -1 & -2 & -1 & 0 \\\\\n","0 & 0 & -1 & 0 & 0\n","\\end{bmatrix}$\n","\n","or applying the parametric Laplacian to the Gaussian to get the filter.\n"]},{"cell_type":"markdown","metadata":{"id":"WCuf9y4LU-6c"},"source":["- SOLUTION 1: Implentation using the mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO EX 2\n","def MarrHildreth_Kernel(img):\n","\n","  # 1. Draw the LoG filter \n","   \n","\n","  # 2. Apply it to the gray image\n"," \n","\n","  # 3. Find the Zero-Crossing\n"," \n","\n","  # 4. Visualization and return the edges "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7X-9pLRqqNou"},"outputs":[],"source":["#SOLUTION 1 OF EX 2\n","def MarrHildreth_Kernel(img):\n","\n","  # 1. Draw the LoG filter \n","  kernel_LoG = np.array([[0,   0, -1,  0,  0],\n","                       [0,  -1, -2, -1,  0],\n","                       [-1, -2, 16, -2, -1],\n","                       [0,  -1, -2, -1,  0],\n","                       [0,   0, -1,  0,  0]])\n"," \n","\n","  # 2. Apply it to the gray image\n","  LoG = cv2.filter2D(grayImg,-1,kernel_LoG)\n","\n","  # 3. Find the Zero-Crossing\n","  ZC = Zero_crossing(LoG)\n","\n","  # 4. Visualization\n","  plt.imshow(ZC, cmap='gray')\n","  return ZC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"elapsed":1211,"status":"ok","timestamp":1666602429335,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"n-2VJvDNPXR0","outputId":"aa51a3bc-f14e-4037-fa20-5841b72b5629"},"outputs":[],"source":["edges = MarrHildreth_Kernel(grayImg)"]},{"cell_type":"markdown","metadata":{"id":"o8-nnB-MVGvC"},"source":["- SOLUTION 2: Implementation by scratch. Hint: use the function `cv2.getGaussianKernel` to generate the gaussian kernel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4woUr1AkU0Pe"},"outputs":[],"source":["#SOLUTION 2 OF EX 2\n","def LoG_filter (sigma=1):\n","  '''given the desired  \"sigma\" of the Gaussian, derive the LoG filter kernel\n","     g =  LoG_filter( sigma=1)'''\n"," \n","  kernel_size=3*2*sigma + 1  \n","  g = cv2.getGaussianKernel(kernel_size, sigma)\n","  g_2D = g*np.transpose(g)\n","  LoG_filter = cv2.Laplacian(g_2D, cv2.CV_64F) \n","  fig = px.imshow(LoG_filter, color_continuous_scale='gray', title='LoG filter')\n","  fig.show()\n","\n","  return LoG_filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Se3LTu3prmf1"},"outputs":[],"source":["def MarrHildreth(img, sigma=1):\n","\n","  # 1. define the LoG filter as a function of sigma\n","  kernel_LoG = LoG_filter(sigma)\n","\n","  # 2. apply it to the image\n","  LoG = cv2.filter2D(img, -1, kernel_LoG)\n","\n","  # 3. Find the zero-crossing\n","  ZC = Zero_crossing(LoG)\n","\n","  #4. Visualization\n","  fig = px.imshow(ZC, color_continuous_scale='gray', title='Zero Crossing')\n","  fig.show()\n","  return ZC\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2072,"status":"ok","timestamp":1666602437366,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"-aoWcv2-cEMG","outputId":"7b68ecb0-abd3-4e67-82a8-41a859955824"},"outputs":[],"source":["edges = MarrHildreth(grayImg, 3)"]},{"cell_type":"markdown","metadata":{"id":"Dqr1ZuRA_jzg"},"source":["### <font color='green'><b>Canny Edge Detection</b></font>\n"]},{"cell_type":"markdown","metadata":{"id":"j7HUZcxHo5Yc"},"source":["### In Opencv \n","\n","OpenCV puts all the above in single function, cv2.Canny(). We will see how to use it.\n","Arguments: \n","1. input image  \n","2. minVal \n","3. maxVal  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"elapsed":1231,"status":"ok","timestamp":1666089695626,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"gDa0SUhV_qJQ","outputId":"8baf035c-7696-4f1c-8dd6-e0bc5d8ba34d"},"outputs":[],"source":["from skimage import img_as_float, img_as_ubyte\n","\n","edges = cv2.Canny(img_as_ubyte(grayImg),100,200) # https://docs.opencv.org/master/da/d22/tutorial_py_canny.html\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(121),plt.imshow(grayImg,cmap = 'gray')\n","plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n","plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n","plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"omT9Wjn5o_9O"},"source":["### Canny edge detection in *Skimage* \n","here we can select the sigma but not the thresholds for the hysteresis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":3393,"status":"ok","timestamp":1666455218667,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"-oF8yXaJoyx9","outputId":"3cbd5a3f-6ad9-4d9f-84b3-ff1fc8f0a86d"},"outputs":[],"source":["from skimage import feature\n","\n","im = rgb2gray(imread(img_dir + 'tiger3.jpg'))\n"," \n","edges1 = feature.canny(im)\n","edges2 = feature.canny(im, sigma=3)\n","fig, (axes1, axes2, axes3) = plt.subplots(nrows=1, ncols=3, figsize=(30,\n","12), sharex=True, sharey=True)\n","axes1.imshow(im, cmap=plt.cm.gray), axes1.axis('off'),\n","axes1.set_title('noisy image', fontsize=50)\n","axes2.imshow(edges1, cmap=plt.cm.gray), axes2.axis('off')\n","axes2.set_title('Canny filter, $\\sigma=1$', fontsize=50)\n","axes3.imshow(edges2, cmap=plt.cm.gray), axes3.axis('off')\n","axes3.set_title('Canny filter, $\\sigma=3$', fontsize=50)\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"awiYzNAasSOJ"},"source":["### <font color='green'><b>Canny Edge Detection step by step </b></font>\n","\n","**OBSERVATION**: the implementation in the cv2 library, does not allow to modify the sigma characterizing the smoothing, and the skimage implamentation, dually does not allow to set the threshold for the hysteresis. \n","Below, Canny step by step with all the parameters free to be set(https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123): "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNC3qPMQ4lWR"},"outputs":[],"source":["from _plotly_utils.colors.sequential import Magenta\n","def grad_filters(img):\n","# first derivative extraction and magnitude and orientation computation\n","\n","    Kx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], np.float32)\n","    Ky = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], np.float32)\n","     \n","    Ix = cv2.filter2D(img, -1, Kx)\n","    Iy = cv2.filter2D(img, -1, Ky)\n","    \n","    mag = np.hypot(Ix, Iy)\n","    mag = mag / mag.max() * 255\n","    theta = np.arctan2(Iy, Ix)\n"," \n","    return (mag, theta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VevJcTma4rTQ"},"outputs":[],"source":["# SKIP details\n","def non_max_suppression(img, D):\n","# INPUT: \n","# - img: magnitude map \n","# - D: orientation map, \n","# OUTPUT:\n","# - Z: filtered \"img\" according to the non-maxima suppression algorithm   \n","  \n","    M, N = img.shape\n","    Z = np.zeros((M,N), dtype=np.int32)\n","    angle = D * 180. / np.pi\n","    angle[angle < 0] += 180\n","     \n","    for i in range(1,M-1):\n","        for j in range(1,N-1):\n","            try:\n","                q = 255\n","                r = 255\n","                \n","               #angle 0\n","                if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n","                    q = img[i, j+1]\n","                    r = img[i, j-1]\n","                #angle 45\n","                elif (22.5 <= angle[i,j] < 67.5):\n","                    q = img[i+1, j-1]\n","                    r = img[i-1, j+1]\n","                #angle 90\n","                elif (67.5 <= angle[i,j] < 112.5):\n","                    q = img[i+1, j]\n","                    r = img[i-1, j]\n","                #angle 135\n","                elif (112.5 <= angle[i,j] < 157.5):\n","                    q = img[i-1, j-1]\n","                    r = img[i+1, j+1]\n","\n","                if (img[i,j] >= q) and (img[i,j] >= r):\n","                    Z[i,j] = img[i,j]\n","                else:\n","                    Z[i,j] = 0\n","\n","            except IndexError as e:\n","                pass\n","    \n","    return Z"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YizIgj6P5AQW"},"outputs":[],"source":["# SKIP details\n","def threshold(img, lowThreshold=10, highThreshold=100):\n"," \n","    M, N = img.shape\n","    res = np.zeros((M,N), dtype=np.int32)\n","    \n","    weak = np.int32(25)\n","    strong = np.int32(255)\n","    \n","    strong_i, strong_j = np.where(img >= highThreshold)\n","    zeros_i, zeros_j = np.where(img < lowThreshold)\n","    \n","    weak_i, weak_j = np.where((img <= highThreshold) & (img >= lowThreshold))\n","    \n","    res[strong_i, strong_j] = strong\n","    res[weak_i, weak_j] = weak\n","    \n","    return (res, weak, strong)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HrfJvtzN5Gmx"},"outputs":[],"source":["# SKIP details\n","def hysteresis(img, lowThreshold=10, highThreshold=100):\n","\n","    [img, weak, strong] = threshold(img, lowThreshold, highThreshold)\n","    M, N = img.shape  \n","    for i in range(1, M-1):\n","        for j in range(1, N-1):\n","            if (img[i,j] == weak):\n","                try:\n","                    if ((img[i+1, j-1] == strong) or (img[i+1, j] == strong) or (img[i+1, j+1] == strong)\n","                        or (img[i, j-1] == strong) or (img[i, j+1] == strong)\n","                        or (img[i-1, j-1] == strong) or (img[i-1, j] == strong) or (img[i-1, j+1] == strong)):\n","                        img[i, j] = strong\n","                    else:\n","                        img[i, j] = 0\n","                except IndexError as e:\n","                    pass\n","    return img"]},{"cell_type":"markdown","metadata":{"id":"WWi2HvjaZ3jI"},"source":["### Main of Canny edge detector "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":674,"status":"ok","timestamp":1666455230940,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"ZvA9dQHh5bK4","outputId":"a3c07880-a7be-4e97-a795-1dd79bc11d76"},"outputs":[],"source":["#Main cannyEdgeDetector\n","sigma=3\n","lowThreshold= 10  \n","highThreshold= 50  \n","kernel_size=3*2*sigma + 1  \n","\n","# load an example image \n","im = imread(img_dir +  'goldengate.jpg')\n","grayImg = rgb2gray(im)\n","\n","# 1. Gaussian filtering \n","g = cv2.getGaussianKernel(kernel_size, sigma)\n","plt.figure()\n","plt.subplot(1,2,1)\n","plt.plot(g)\n","\n","g_2D = g*np.transpose(g)\n","plt.subplot(1,2 ,2)\n","plt.imshow(g_2D)\n","plt.title('Gaussioan Kernel')\n","\n","smoothed= cv2.filter2D (grayImg, -1, g_2D)\n","\n","# 2. First derivative\n","[M, theta] = grad_filters(smoothed)\n","\n","#3. Non_max_suppression\n","Selected = non_max_suppression(M, theta)\n","\n","#4. Hysteresis \n","edges = hysteresis(Selected, lowThreshold, highThreshold)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","fig = px.imshow(edges, color_continuous_scale='gray', title= 'Canny edge detection')\n","fig.show() "]},{"cell_type":"markdown","metadata":{"id":"gJwtCG_R9Pvw"},"source":["#### <font color='green'><b>EXERCISE 3 </b></font>\n"," \n","Write a function `cannyParametric()` explointing the script above, while instead of applying the Gaussian and the gradient filters separately, adopt the Derivative of Gaussian \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_pO5Btu9dHM"},"outputs":[],"source":["#TO DO\n","def DoG_kernel(sigma=1):\n","\n","    '''Given the desired  \"sigma\" of the Gaussian, \n","       define the filters, Fx and Fy, corresponding to the partial derivatives of the Gaussian'''\n","    \n","   #1. define the Gaussian filter  \n","   \n","    \n","\n","   #2. define the derivantive kernels\n","     \n","   #3. compute the derivatives of the Gaussian\n","     \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TO DO\n","def DoG_first_derivative (img,   sigma=1):\n","  # given the gray scale image \"img\", and the desired  \"sigma\" of the Gaussian:\n","\n","  # 1. derive the DoG filter kernels\n","     \n","  \n","  # 2. apply them to \"img\"\n","    \n","\n","  # 3. compute and return the magnitude \"mag\" and orientation map \"theta\"\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVsK7VDKALog"},"outputs":[],"source":["#SOLUTION OF EX 3\n","def DoG_kernel(sigma=1):\n","    \n","    '''Given the desired  \"sigma\" of the Gaussian, \n","       define the filters, Fx and Fy, corresponding to the partial derivatives of the Gaussian'''\n","    \n","    #TO DO\n","\n","    #1. define the Gaussian filter  \n","    kernel_size=3*2*sigma + 1   \n","    g = cv2.getGaussianKernel(kernel_size, sigma)\n","    g_2D = g*np.transpose(g)\n","\n","    #2. define the derivantive kernels\n","    Kx = np.array([[-1, 0, 1], \n","                   [-1, 0, 1], \n","                   [-1, 0, 1]], np.float32)\n","    Ky = np.array([[1, 1, 1], \n","                   [0, 0, 0], \n","                   [-1, -1, -1]], np.float32)\n","    \n","    #3. compute the derivatives of the Gaussian\n","    Fx = cv2.filter2D(g_2D, -1, Kx)\n","    Fy = cv2.filter2D(g_2D, -1, Ky)\n","    \n","    \n","    return (Fx, Fy)\n","    \n","def DoG_first_derivative (img,   sigma=1):\n","  # given the gray scale image \"img\", and the desired  \"sigma\" of the Gaussian:\n","\n","  # 1. derive the DoG filter kernels\n","    [Fx, Fy] = DoG_kernel(sigma) \n","  \n","  # 2. apply them to \"img\"\n","    Ix = cv2.filter2D(img,-1, Fx)\n","    Iy = cv2.filter2D(img, -1, Fy)\n","\n","  # 3. compute and return the magnitude \"mag\" and orientation map \"theta\"\n","    mag = np.hypot(Ix, Iy)\n","    mag = mag / mag.max() * 255\n","    theta = np.arctan2(Iy, Ix)\n","     \n","    return (mag, theta)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uw08ZvdS9c0_"},"outputs":[],"source":["#Canny main, (GIVEN)\n","def cannyParametric(img, sigma=1, lowThreshold=10, highThreshold=200):  \n","  # img: gray level image\n","  # sigma: sigma of the gaussian filter\n","  # lowThreshold: low threshold for the hysteresis thresholding\n","  # highThreshold: high threshold for the hysteresis thresholding\n","\n","  # 1. First derivative using Derivative of Gaussian\n","  [M, theta] = DoG_first_derivative(img, sigma)\n","\n","  #2. Non_max_suppression\n","  Selected = non_max_suppression(M, theta)\n","\n","  #3. Hysteresis \n","  edges = hysteresis(Selected, lowThreshold, highThreshold)\n","\n","  fig = px.imshow(edges, color_continuous_scale='gray', title= 'Canny edge detection')\n","  fig.show() \n","  return edges "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1443,"status":"ok","timestamp":1666455525966,"user":{"displayName":"Raffaella Lanzarotti","userId":"13623836324684543005"},"user_tz":-120},"id":"FMMrUql-WGhb","outputId":"4b5c62f8-4685-4fc9-9efc-3e4eeb1c3ec0"},"outputs":[],"source":["from skimage import img_as_ubyte\n","\n","edges = cannyParametric(img_as_ubyte(grayImg),1, 5, 50)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNaMblxmMezpwy2IYGmPxf2","collapsed_sections":["phes8QASTNWD","uDVV2F1aTgh1"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
